apiVersion: v1
kind: Pod
metadata:
  name: rer-savia-llm
  namespace: rer-savia
spec:
  containers:
    - command: ["/bin/sh","-c"]
      args: ["python flask_client.py"]
#      image: harbor-core.prod.margherita.ad.lepida.it/savia-test/test_savia_llm:latest
      image: harbor-core.prod.margherita.ad.lepida.it/savia-test/test_savia_llm_small:latest
      envFrom:
      - configMapRef:         
          name: hf-auth-token
      imagePullPolicy: IfNotPresent
      ports:
        - containerPort: 5000
      volumeMounts:
      - mountPath: /checkpoints
        name: checkpoints
      - mountPath: /LLM
        name: llm
      - mountPath: /LLM_small
        name: llmsmall
      name: savia-test-llm
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      resources:
        limits:
          nvidia.com/gpu: 2
          memory: 30Gi
          cpu: "16"
        requests:
          memory: 8Gi
          cpu: "8"
  volumes:
  - name: checkpoints
    persistentVolumeClaim: 
      claimName: checkpoints
  - name: llm
    persistentVolumeClaim: 
      claimName: llm
  - name: llmsmall
    persistentVolumeClaim: 
      claimName: llmsmall
  metadata:
    namespace: rer-savia
  runtimeClassName: nvidia
